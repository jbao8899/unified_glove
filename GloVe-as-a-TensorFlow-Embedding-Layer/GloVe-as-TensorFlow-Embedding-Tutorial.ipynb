{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe as a TensorFlow Embedding layer\n",
    "\n",
    "In this tutorial, we'll see how to convert GloVe embeddings to TensorFlow layers. This could also work with embeddings generated from word2vec.\n",
    "\n",
    "First, we'll download the embedding we need. \n",
    "\n",
    "Second, we'll load it into TensorFlow to convert input words with the embedding to word features. The conversion is done within TensorFlow, so it is GPU-optimized and it could run on batches on the GPU. It is also possible to run this tutorial with just a CPU. We'll play with word representations once the embedding is loaded. \n",
    "\n",
    "What you'll need: \n",
    "- A working installation of TensorFlow.\n",
    "- 4 to 6 GB of disk space to download embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, some theory\n",
    "\n",
    "### Representations\n",
    "\n",
    "We need a way to represent content in neural networks. For audio, it's possible to use a [spectrogram](https://github.com/guillaume-chevalier/filtering-stft-and-laplace-transform). For images, it's possible to directly use the pixels and then get features maps from a convolutional neural network. For text, analyzing every letter is costly, so it's better to use word representations to embed words or documents as vectors into Artificial Neural Networks and other Machine Learning algorithms. \n",
    "> ![Features from content](https://www.tensorflow.org/images/audio-image-text.png)\n",
    "> https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "As described by Keras, an embedding:\n",
    "\n",
    "> \"Turns positive integers (indexes) into dense vectors of fixed size\".\n",
    "\n",
    "That's it. It's to extract features from words. An embedding is a huge matrix for which each row is a word, and each column is a feature from that word. To summarize, it's possible to convert a word to a vector of a certain length, such as 25, or 100, 200, 1000, and on. In practice, a length of 100 to 300 features is acceptable. With less than 100, we would risk underfitting our linguistic dataset. Word embeddings can eat a lot of RAM, so in this tutorial we'll download and use dimensions of size 25, however changing that to 200 would be a breeze with the actual code. \n",
    "\n",
    "### You can compute word analogies\n",
    "\n",
    "The word representations (features) are linear, therefore it's possible to add and substract words with word embeddings. For example, here's the most known word analogy example:\n",
    "\n",
    "<!--- $$\\text{King} - \\text{Man} = \\text{Queen} - \\text{Woman}$$ -->\n",
    "<!--- $$\\Longleftrightarrow$$ -->\n",
    "<!--- $$\\text{King} - \\text{Man} + \\text{Woman} = \\text{Queen}$$ -->\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/guillaume-chevalier/GloVe-as-TensorFlow-Embedding/master/images/word_analogy.png\" />\n",
    "</p>\n",
    "\n",
    " For example, it's possible to change from: \n",
    "- Masculine and feminine\n",
    "- Country and capital\n",
    "- Singular and plural\n",
    "- Verb tenses\n",
    "- And the list goes on...\n",
    "\n",
    "> ![Word features from embeddings](https://www.tensorflow.org/images/linear-relationships.png)\n",
    "> https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "It's also possible to compute the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) between a word A and a word B, which is the cosine of the angle between the two words. A cosine similarity of -1 would mean the words are complete opposites, while a cosine similarity of 1 would mean that the words are the same. Here's the formula to compare two words: \n",
    "\n",
    "<!--- $$\\text{Cosine Similarity}=cos({\\theta}_{AB})=\\frac{A \\cdot B}{|A|_2 |B|_2}$$ -->\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/guillaume-chevalier/GloVe-as-TensorFlow-Embedding/master/images/cosine_similarity.png\" />\n",
    "</p>\n",
    "\n",
    "Here, the norm (such as |A|₂) is the **L2 norm**, the radius in space from the origin, but in a higher dimensional space such as with $n=300$: \n",
    "\n",
    "<!--- $$|A|_2=\\sqrt{A_1 + A_2 + A_3 + ... + A_n}$$ -->\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/guillaume-chevalier/GloVe-as-TensorFlow-Embedding/master/images/L2_norm.png\" />\n",
    "</p>\n",
    "\n",
    "### How does it looks like concretely?\n",
    "\n",
    "For example, here are some cosine similarities to the word \"king\", computed from the code explained below: \n",
    "\n",
    "| Other Word | Cosine Similarity |\n",
    "| ---------- | ----------------- |\n",
    "| prince:    |   0.933741,       |\n",
    "| queen:     |   0.9202421,      |\n",
    "| aka:       |   0.91769224,     |\n",
    "| lady:      |   0.9163239,      |\n",
    "| jack:      |   0.91473544,     |\n",
    "| 's:        |   0.90668976,     |\n",
    "| stone:     |   0.8982374,      |\n",
    "| mr.:       |   0.89194083,     |\n",
    "| the:       |   0.88934386,     |\n",
    "| star:      |   0.88920873,     |\n",
    "\n",
    "Finally, notice how similar words are close in space: \n",
    "> ![](https://www.tensorflow.org/images/embedding-nearest-points.png)\n",
    "> https://www.tensorflow.org/programmers_guide/embedding\n",
    "\n",
    "Note: in the image above, the embedding have been subsampled to a lower 3D space with a PCA (Princial Component Analysis) or t-SNE (t-distributed Stochastic Neighbor Embedding) to be explorable. This is possible with TensorBoard for inspection. 300 dimensions can't be visualised easily. \n",
    "\n",
    "### But how are those word representations obtained?\n",
    "\n",
    "Before continuing to the practical part where we'll use pretrained embeddings, it's a good thing to know that embeddings can be obtained from unsupervised training on large datasets of text. That's at least a way we can use the text off the internet! To perform this training to get an embedding, it's possible to go with the word2vec approach, or also with the GloVe (Global word Vectors). GloVe is a more recent approach that builds upon the theory of word2vec. Here, we'll use GloVe embeddings. To summarize how the unsupervised training happens, let's see what John Rupert Firth has to say: \n",
    "\n",
    "> You shall know a word by the company it keeps (Firth, J. R., 1957)\n",
    "\n",
    "It's amazing that by comparing words and trying to guess the surrounding words, it's possible to find their meaning. To learn more on that, I'd recommend you the [5th course of the Deep Learning Specialization](https://www.coursera.org/learn/nlp-sequence-models) on coursera by Andrew Ng, a course which can lead to the Deep Learning Specialization [certificate](https://www.coursera.org/account/accomplishments/specialization/U7VNC3ZD9YD8). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get practical! \n",
    "\n",
    "### First, download the pretrained embeddings with the code below\n",
    "\n",
    "Careful, the download will take 4-6 GB on disks. If you have already downloaded the embeddings, they will be located under the `./embeddings/` folder relative to here, and won't be downloaded again. \n",
    "\n",
    "Note: several embeddings were downloaded with different dimension sizes in the zip file, but we only need one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\964864\\OneDrive - Cognizant HealthCare\\Documents\\Innovation Project\\Unified GloVe\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\964864\\AppData\\Local\\Temp\\1\\ipykernel_22280\\4183875365.py:12: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\964864\\OneDrive - Cognizant HealthCare\\Documents\\Innovation Project\\Unified GloVe\\.venv\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import chakin\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow.compat.v1 as tf # REPLACED!!!!\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function search in module chakin.downloader:\n",
      "\n",
      "search(lang='')\n",
      "    Search pre-trained word vectors by their language\n",
      "    :param lang: str, default ''\n",
      "    :return: None\n",
      "        print search result as pandas DataFrame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(chakin.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  Dimension                     Corpus VocabularySize  \\\n",
      "2          fastText(en)        300                  Wikipedia           2.5M   \n",
      "11         GloVe.6B.50d         50  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "12        GloVe.6B.100d        100  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "13        GloVe.6B.200d        200  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "14        GloVe.6B.300d        300  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "15       GloVe.42B.300d        300          Common Crawl(42B)           1.9M   \n",
      "16      GloVe.840B.300d        300         Common Crawl(840B)           2.2M   \n",
      "17    GloVe.Twitter.25d         25               Twitter(27B)           1.2M   \n",
      "18    GloVe.Twitter.50d         50               Twitter(27B)           1.2M   \n",
      "19   GloVe.Twitter.100d        100               Twitter(27B)           1.2M   \n",
      "20   GloVe.Twitter.200d        200               Twitter(27B)           1.2M   \n",
      "21  word2vec.GoogleNews        300          Google News(100B)           3.0M   \n",
      "\n",
      "      Method Language    Author  \n",
      "2   fastText  English  Facebook  \n",
      "11     GloVe  English  Stanford  \n",
      "12     GloVe  English  Stanford  \n",
      "13     GloVe  English  Stanford  \n",
      "14     GloVe  English  Stanford  \n",
      "15     GloVe  English  Stanford  \n",
      "16     GloVe  English  Stanford  \n",
      "17     GloVe  English  Stanford  \n",
      "18     GloVe  English  Stanford  \n",
      "19     GloVe  English  Stanford  \n",
      "20     GloVe  English  Stanford  \n",
      "21  word2vec  English    Google  \n"
     ]
    }
   ],
   "source": [
    "chakin.search(lang='English')\n",
    "\n",
    "# Twitter is garbage\n",
    "# Look at 300-dimension Wikipedia and Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings\\glove.840B.300d.zip\n",
      "Embeddings already downloaded.\n",
      "Embeddings already extracted.\n"
     ]
    }
   ],
   "source": [
    "# ENTER THE INDEX YOU WISH TO USE\n",
    "# Use 2 for the 300 dimension embeddings created using fastText on Wikipedia data\n",
    "# Use 16 for the 300 dimension embeddings created using GloVe on Common Crawl data\n",
    "# Use 17 for the 25 dimension embeddings created using GloVe on Twitter data\n",
    "# Other embedding schemes are not supported and may require further code modification to work.\n",
    "# As a side note, chakin does not seem well implemented.\n",
    "# The Common Crawl (index 16) embeddings are impossible to download using the library, \n",
    "# and must be downloaded manually from https://github.com/stanfordnlp/GloVe.\n",
    "# The formats are inconsistent, with the Wikipedia data (index 2) consisting of a single file\n",
    "# compressed as a .gz file, and the other two embeddings described here compressed as .zip files.\n",
    "# Also, the 25-D Twitter embeddings (index 17) comes packed together with the 50-D, 100-D, and 200-D\n",
    "# Twitter embeddings, even though chakin lets us choose between them,\n",
    "# while the Common Crawl (index 16) 300-d embeddings come by themselves\n",
    "# Additionally, the Wikipedia embedding file has a header line that cannot be parsed by\n",
    "# the provided code and which must be removed, while the other embedding files do not\n",
    "\n",
    "CHAKIN_INDEX = 16\n",
    "\n",
    "if CHAKIN_INDEX == 2:\n",
    "    NUMBER_OF_DIMENSIONS = 300\n",
    "    FILE_NAME = \"cc.en.300.vec\"\n",
    "\n",
    "    DATA_FOLDER = \"embeddings\"\n",
    "    GZ_FILE = os.path.join(DATA_FOLDER, \"{}.gz\".format(FILE_NAME))\n",
    "\n",
    "    GLOVE_FILENAME = os.path.join(DATA_FOLDER, FILE_NAME)\n",
    "\n",
    "    if not os.path.exists(GZ_FILE) and not os.path.exists(GLOVE_FILENAME):\n",
    "        # GloVe by Stanford is licensed Apache 2.0: \n",
    "        #     https://github.com/stanfordnlp/GloVe/blob/master/LICENSE\n",
    "        #     http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "        #     Copyright 2014 The Board of Trustees of The Leland Stanford Junior University\n",
    "        print(\"Downloading embeddings to '{}'\".format(GZ_FILE))\n",
    "        chakin.download(number=CHAKIN_INDEX, save_dir='./{}'.format(DATA_FOLDER))\n",
    "    else:\n",
    "        print(\"Embeddings already downloaded.\")\n",
    "        \n",
    "    if not os.path.exists(GLOVE_FILENAME):\n",
    "        print(\"Extracting embeddings to '{}'\".format(GLOVE_FILENAME))\n",
    "\n",
    "        with gzip.open(GZ_FILE, \"rt\", encoding=\"utf-8\") as f_in, open(GLOVE_FILENAME, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            chunk_size = 1024 # Read one chunk at a time, to avoid filling up RAM\n",
    "            \n",
    "            is_first_chunk = True\n",
    "            while True:\n",
    "                chunk = f_in.read(chunk_size)\n",
    "                if is_first_chunk:\n",
    "                    # We need to omit the first line of the embedding file, as it\n",
    "                    # contains a header that the provided code cannot parse\n",
    "                    chunk = chunk.split(\"\\n\", maxsplit=1)[1] # index 0 will contain \"2000000 300\"\n",
    "                    is_first_chunk = False\n",
    "                f_out.write(chunk)\n",
    "                # We are done\n",
    "                if (len(chunk)) <= 0:\n",
    "                    break\n",
    "\n",
    "    else:\n",
    "        print(\"Embeddings already extracted.\")\n",
    "elif CHAKIN_INDEX == 16:\n",
    "    NUMBER_OF_DIMENSIONS = 300\n",
    "    SUBFOLDER_NAME = \"glove.840B.300d\"\n",
    "\n",
    "    DATA_FOLDER = \"embeddings\"\n",
    "    ZIP_FILE = os.path.join(DATA_FOLDER, \"{}.zip\".format(SUBFOLDER_NAME))\n",
    "    UNZIP_FOLDER = os.path.join(DATA_FOLDER, SUBFOLDER_NAME)\n",
    "\n",
    "\n",
    "    print(ZIP_FILE)\n",
    "\n",
    "    GLOVE_FILENAME = os.path.join(UNZIP_FOLDER, \"{}.txt\".format(SUBFOLDER_NAME))\n",
    "\n",
    "    if not os.path.exists(ZIP_FILE) and not os.path.exists(UNZIP_FOLDER):\n",
    "        print(\"Please download glove.840B.300d.zip from https://github.com/stanfordnlp/GloVe and put it into the embeddings folder.\")\n",
    "        print(\"It is no longer available for download from the chakin library\")\n",
    "        assert(False)\n",
    "    else:\n",
    "        print(\"Embeddings already downloaded.\")\n",
    "        \n",
    "    if not os.path.exists(UNZIP_FOLDER):\n",
    "        with zipfile.ZipFile(ZIP_FILE,\"r\") as zip_ref:\n",
    "            print(\"Extracting embeddings to '{}'\".format(UNZIP_FOLDER))\n",
    "            zip_ref.extractall(UNZIP_FOLDER)\n",
    "    else:\n",
    "        print(\"Embeddings already extracted.\")\n",
    "elif CHAKIN_INDEX == 17:\n",
    "    NUMBER_OF_DIMENSIONS = 25\n",
    "    SUBFOLDER_NAME = \"glove.twitter.27B\"\n",
    "\n",
    "    DATA_FOLDER = \"embeddings\"\n",
    "    ZIP_FILE = os.path.join(DATA_FOLDER, \"{}.zip\".format(SUBFOLDER_NAME))\n",
    "    UNZIP_FOLDER = os.path.join(DATA_FOLDER, SUBFOLDER_NAME)\n",
    "\n",
    "    GLOVE_FILENAME = os.path.join(UNZIP_FOLDER, \"{}.{}d.txt\".format(SUBFOLDER_NAME, NUMBER_OF_DIMENSIONS))\n",
    "\n",
    "    if not os.path.exists(ZIP_FILE) and not os.path.exists(UNZIP_FOLDER):\n",
    "        # GloVe by Stanford is licensed Apache 2.0: \n",
    "        #     https://github.com/stanfordnlp/GloVe/blob/master/LICENSE\n",
    "        #     http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "        #     Copyright 2014 The Board of Trustees of The Leland Stanford Junior University\n",
    "        print(\"Downloading embeddings to '{}'\".format(ZIP_FILE))\n",
    "        chakin.download(number=CHAKIN_INDEX, save_dir='./{}'.format(DATA_FOLDER))\n",
    "    else:\n",
    "        print(\"Embeddings already downloaded.\")\n",
    "        \n",
    "    if not os.path.exists(UNZIP_FOLDER):\n",
    "        with zipfile.ZipFile(ZIP_FILE,\"r\") as zip_ref:\n",
    "            print(\"Extracting embeddings to '{}'\".format(UNZIP_FOLDER))\n",
    "            zip_ref.extractall(UNZIP_FOLDER)\n",
    "    else:\n",
    "        print(\"Embeddings already extracted.\")\n",
    "else:\n",
    "    print(\"Those embeddings are not currently supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read the embedding from disks here\n",
    "\n",
    "First, we load the embeddings, then we demonstrate their usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_from_disks(glove_filename, with_indexes=True):\n",
    "    \"\"\"\n",
    "    Read a GloVe txt file. If `with_indexes=True`, we return a tuple of two dictionnaries\n",
    "    `(word_to_index_dict, index_to_embedding_array)`, otherwise we return only a direct \n",
    "    `word_to_embedding_dict` dictionnary mapping from a string to a numpy array.\n",
    "    \"\"\"\n",
    "    if with_indexes:\n",
    "        word_to_index_dict = dict()\n",
    "        index_to_embedding_array = []\n",
    "    else:\n",
    "        word_to_embedding_dict = dict()\n",
    "\n",
    "    \n",
    "    with open(glove_filename, 'r', encoding=\"utf8\") as glove_file: # Needed to add encoding=\"utf8\"!!!!!\n",
    "        for (i, line) in enumerate(glove_file):\n",
    "            \n",
    "            split = line.split(' ')\n",
    "            \n",
    "            word = split[0]\n",
    "            \n",
    "            representation = split[1:]\n",
    "            representation = np.array(\n",
    "                [float(val) for val in representation]\n",
    "            )\n",
    "            \n",
    "            if with_indexes:\n",
    "                word_to_index_dict[word] = i\n",
    "                index_to_embedding_array.append(representation)\n",
    "            else:\n",
    "                word_to_embedding_dict[word] = representation\n",
    "\n",
    "    _WORD_NOT_FOUND = [0.0]* len(representation)  # Empty representation for unknown words.\n",
    "    if with_indexes:\n",
    "        _LAST_INDEX = i + 1\n",
    "        word_to_index_dict = defaultdict(lambda: _LAST_INDEX, word_to_index_dict)\n",
    "        index_to_embedding_array = np.array(index_to_embedding_array + [_WORD_NOT_FOUND])\n",
    "        return word_to_index_dict, index_to_embedding_array\n",
    "    else:\n",
    "        word_to_embedding_dict = defaultdict(lambda: _WORD_NOT_FOUND)\n",
    "        return word_to_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding from disks...\n",
      "Embedding loaded from disks.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading embedding from disks...\")\n",
    "word_to_index, index_to_embedding = load_embedding_from_disks(GLOVE_FILENAME, with_indexes=True)\n",
    "print(\"Embedding loaded from disks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown words have representations with values of zero, such as [0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding is of shape: (2196019, 300)\n",
      "This means (number of words, number of dimensions per word)\n",
      "\n",
      "The first words are words that tend occur more often.\n",
      "Note: for unknown words, the representation is an empty vector,\n",
      "and the index is the last one. The dictionnary has a limit:\n",
      "    A word --> Index in embedding --> Representation\n",
      "    worsdfkljsdf --> 2196018 --> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "    the --> 2 --> [0.27204, -0.06203, -0.1884, 0.023225, -0.018158, 0.0067192, -0.13877, 0.17708, 0.17709, 2.5882, -0.35179, -0.17312, 0.43285, -0.10708, 0.15006, -0.19982, -0.19093, 1.1871, -0.16207, -0.23538, 0.003664, -0.19156, -0.085662, 0.039199, -0.066449, -0.04209, -0.19122, 0.011679, -0.37138, 0.21886, 0.0011423, 0.4319, -0.14205, 0.38059, 0.30654, 0.020167, -0.18316, -0.0065186, -0.0080549, -0.12063, 0.027507, 0.29839, -0.22896, -0.22882, 0.14671, -0.076301, -0.1268, -0.0066651, -0.052795, 0.14258, 0.1561, 0.05551, -0.16149, 0.09629, -0.076533, -0.049971, -0.010195, -0.047641, -0.16679, -0.2394, 0.0050141, -0.049175, 0.013338, 0.41923, -0.10104, 0.015111, -0.077706, -0.13471, 0.119, 0.10802, 0.21061, -0.051904, 0.18527, 0.17856, 0.041293, -0.014385, -0.082567, -0.035483, -0.076173, -0.045367, 0.089281, 0.33672, -0.22099, -0.0067275, 0.23983, -0.23147, -0.88592, 0.091297, -0.012123, 0.013233, -0.25799, -0.02972, 0.016754, 0.01369, 0.32377, 0.039546, 0.042114, -0.088243, 0.30318, 0.087747, 0.16346, -0.40485, -0.043845, -0.040697, 0.20936, -0.77795, 0.2997, 0.2334, 0.14891, -0.39037, -0.053086, 0.062922, 0.065663, -0.13906, 0.094193, 0.10344, -0.2797, 0.28905, -0.32161, 0.020687, 0.063254, -0.23257, -0.4352, -0.017049, -0.32744, -0.047064, -0.075149, -0.18788, -0.015017, 0.029342, -0.3527, -0.044278, -0.13507, -0.11644, -0.1043, 0.1392, 0.0039199, 0.37603, 0.067217, -0.37992, -1.1241, -0.057357, -0.16826, 0.03941, 0.2604, -0.023866, 0.17963, 0.13553, 0.2139, 0.052633, -0.25033, -0.11307, 0.22234, 0.066597, -0.11161, 0.062438, -0.27972, 0.19878, -0.36262, -1.0006e-05, -0.17262, 0.29166, -0.15723, 0.054295, 0.06101, -0.39165, 0.2766, 0.057816, 0.39709, 0.025229, 0.24672, -0.08905, 0.15683, -0.2096, -0.22196, 0.052394, -0.01136, 0.050417, -0.14023, -0.042825, -0.031931, -0.21336, -0.20402, -0.23272, 0.07449, 0.088202, -0.11063, -0.33526, -0.014028, -0.29429, -0.086911, -0.1321, -0.43616, 0.20513, 0.0079362, 0.48505, 0.064237, 0.14261, -0.43711, 0.12783, -0.13111, 0.24673, -0.27496, 0.15896, 0.43314, 0.090286, 0.24662, 0.066463, -0.20099, 0.1101, 0.03644, 0.17359, -0.15689, -0.086328, -0.17316, 0.36975, -0.40317, -0.064814, -0.034166, -0.013773, 0.062854, -0.17183, -0.12366, -0.034663, -0.22793, -0.23172, 0.239, 0.27473, 0.15332, 0.10661, -0.060982, -0.024805, -0.13478, 0.17932, -0.37374, -0.02893, -0.11142, -0.08389, -0.055932, 0.068039, -0.10783, 0.1465, 0.094617, -0.084554, 0.067429, -0.3291, 0.034082, -0.16747, -0.25997, -0.22917, 0.020159, -0.02758, 0.16136, -0.18538, 0.037665, 0.57603, 0.20684, 0.27941, 0.16477, -0.018769, 0.12062, 0.069648, 0.059022, -0.23154, 0.24095, -0.3471, 0.04854, -0.056502, 0.41566, -0.43194, 0.4823, -0.051759, -0.27285, -0.25893, 0.16555, -0.1831, -0.06734, 0.42457, 0.010346, 0.14237, 0.25939, 0.17123, -0.13821, -0.066846, 0.015981, -0.30193, 0.043579, -0.043102, 0.35025, -0.19681, -0.4281, 0.16899, 0.22511, -0.28557, -0.1028, -0.018168, 0.11407, 0.13015, -0.18317, 0.1323]\n",
      "    aewaiuhUGRYUgreu --> 2196018 --> [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "vocab_size, embedding_dim = index_to_embedding.shape\n",
    "print(\"Embedding is of shape: {}\".format(index_to_embedding.shape))\n",
    "print(\"This means (number of words, number of dimensions per word)\\n\")\n",
    "print(\"The first words are words that tend occur more often.\")\n",
    "\n",
    "print(\"Note: for unknown words, the representation is an empty vector,\\n\"\n",
    "      \"and the index is the last one. The dictionnary has a limit:\")\n",
    "print(\"    {} --> {} --> {}\".format(\"A word\", \"Index in embedding\", \"Representation\"))\n",
    "word = \"worsdfkljsdf\"\n",
    "idx = word_to_index[word]\n",
    "embd = list(np.array(index_to_embedding[idx], dtype=int))  # \"int\" for compact print only.\n",
    "print(\"    {} --> {} --> {}\".format(word, idx, embd))\n",
    "word = \"the\"\n",
    "idx = word_to_index[word]\n",
    "embd = list(index_to_embedding[idx])  # \"int\" for compact print only.\n",
    "print(\"    {} --> {} --> {}\".format(word, idx, embd))\n",
    "\n",
    "# Added\n",
    "word = \"aewaiuhUGRYUgreu\"\n",
    "idx = word_to_index[word]\n",
    "embd = list(index_to_embedding[idx])  # \"int\" for compact print only.\n",
    "print(\"    {} --> {} --> {}\".format(word, idx, embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.082752   0.67204   -0.14987   -0.064983   0.056491   0.40228\n",
      "  0.0027747 -0.3311    -0.30691    2.0817     0.031819   0.013643\n",
      "  0.30265    0.0071297 -0.5819    -0.2774    -0.062254   1.1451\n",
      " -0.24232    0.1235    -0.12243    0.33152   -0.006162  -0.30541\n",
      " -0.13057   -0.054601   0.037083  -0.070552   0.5893    -0.30385\n",
      "  0.2898    -0.14653   -0.27052    0.37161    0.32031   -0.29125\n",
      "  0.0052483 -0.13212   -0.052736   0.087349  -0.26668   -0.16897\n",
      "  0.015162  -0.0083746 -0.14871    0.23413   -0.20719   -0.091386\n",
      "  0.40075   -0.17223    0.18145    0.37586   -0.28682    0.37289\n",
      " -0.16185    0.18008    0.3032    -0.13216    0.18352    0.095759\n",
      "  0.094916   0.008289   0.11761    0.34046    0.03677   -0.29077\n",
      "  0.058303  -0.027814   0.082941   0.1862    -0.031494   0.27985\n",
      " -0.074412  -0.13762   -0.21866    0.18138    0.040855  -0.113\n",
      "  0.24107    0.3657    -0.27525   -0.05684    0.34872    0.011884\n",
      "  0.14517   -0.71395    0.48497    0.14807    0.62287    0.20599\n",
      "  0.58379   -0.13438    0.40207    0.18311    0.28021   -0.42349\n",
      " -0.25626    0.17715   -0.54095    0.16596   -0.036058   0.08499\n",
      " -0.64989    0.075549  -0.28831    0.40626   -0.2802     0.094062\n",
      "  0.32406    0.28437   -0.26341    0.11553    0.071918  -0.47215\n",
      " -0.18366   -0.34709    0.29964   -0.66514    0.002516  -0.42333\n",
      "  0.27512    0.36012    0.16311    0.23964   -0.05923    0.3261\n",
      "  0.20559    0.038677  -0.045816   0.089764   0.43151   -0.15954\n",
      "  0.08532   -0.26572   -0.15001    0.084286  -0.16714   -0.43004\n",
      "  0.060807   0.13121   -0.24112    0.66554    0.4453    -0.18019\n",
      " -0.13919    0.56252    0.21457   -0.46443   -0.012211   0.029988\n",
      " -0.051094  -0.20135    0.80788    0.47377   -0.057647   0.46216\n",
      "  0.16084   -0.20954   -0.05452    0.15572   -0.13712    0.12972\n",
      " -0.011936  -0.003378  -0.13595   -0.080711   0.20065    0.054056\n",
      "  0.046816   0.059539   0.046265   0.17754   -0.31094    0.28119\n",
      " -0.24355    0.085252  -0.21011   -0.19472    0.0027297 -0.46341\n",
      "  0.14789   -0.31517   -0.065939   0.036106   0.42903   -0.33759\n",
      "  0.16432    0.32568   -0.050392  -0.054297   0.24074    0.41923\n",
      "  0.13012   -0.17167   -0.37808   -0.23089   -0.019477  -0.29291\n",
      " -0.30824    0.30297   -0.22659    0.081574  -0.18516   -0.21408\n",
      "  0.40616   -0.28974    0.074174  -0.17795    0.28595   -0.039626\n",
      " -0.2339    -0.36054   -0.067503  -0.091065   0.23438   -0.0041331\n",
      "  0.003232   0.0072134  0.008697   0.21614    0.049904   0.35582\n",
      "  0.13748    0.073361   0.14166    0.2412    -0.013322   0.15613\n",
      "  0.083381   0.088146  -0.019357   0.43795    0.083961   0.45309\n",
      " -0.50489   -0.10865   -0.2527    -0.18251    0.20441    0.13319\n",
      "  0.1294     0.050594  -0.15612   -0.39543    0.12538    0.24881\n",
      " -0.1927    -0.31847   -0.12719    0.4341     0.31177   -0.0040946\n",
      " -0.2094    -0.079961   0.1161    -0.050794   0.015266  -0.2803\n",
      " -0.12486    0.23587    0.2339    -0.14023    0.028462   0.56923\n",
      " -0.1649    -0.036429   0.010051  -0.17107   -0.042608   0.044965\n",
      " -0.4393    -0.26137    0.30088   -0.060772  -0.45312   -0.19076\n",
      " -0.20288    0.27694   -0.060888   0.11944    0.62206   -0.19343\n",
      "  0.47849   -0.30113    0.059389   0.074901   0.061068  -0.4662\n",
      "  0.40054   -0.19099   -0.14331    0.018267  -0.18643    0.20709\n",
      " -0.35598    0.05338   -0.050821  -0.1918    -0.37846   -0.06589  ]\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "# Look at one of the embedding vectors and the word it represents\n",
    "print(index_to_embedding[0])\n",
    "for word in word_to_index.keys():\n",
    "    if word_to_index[word] == 0:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The L2 norm of some words can vary\n",
    "Notice how more common words have a longer embedding norm, how some text on Twitter was in French, and how it deals with punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The:           4.709349891895434\n",
      "Teh:           6.929913774699059\n",
      "A:             5.306696239670178\n",
      "It:            4.940976347088982\n",
      "Its:           5.6994022787014424\n",
      "Bacon:         7.252612813214055\n",
      "Star:          6.804042131778104\n",
      "Clone:         6.326065057352606\n",
      "Bonjour:       6.961348818803134\n",
      "Intelligence:  7.082624039779232\n",
      "À:             8.446534394969143\n",
      "A:             5.306696239670178\n",
      "Ça:            8.33402193877499\n",
      "Ca:            5.479705953036163\n",
      "Été:           7.607633619292368\n",
      "C'est:         7.635576121212556\n",
      "Aujourd'hui:   0.0\n",
      "Aujourd:       7.124803532887244\n",
      "':             6.1379290208952595\n",
      "hui:           7.287160749674351\n",
      "?:             5.160823253233168\n",
      "!:             5.620569023196788\n",
      ",:             5.094723344738617\n",
      ".:             4.931635594482644\n",
      "-:             5.603344705010764\n",
      "/:             5.907700055660746\n",
      "~:             5.99084175122729\n",
      "Note: here we printed words starting with capital letters, \n",
      "however to take their embeddings we need their lowercase version (str.lower())\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    \"The\", \"Teh\", \"A\", \"It\", \"Its\", \"Bacon\", \"Star\", \"Clone\", \"Bonjour\", \"Intelligence\", \n",
    "    \"À\", \"A\", \"Ça\", \"Ca\", \"Été\", \"C'est\", \"Aujourd'hui\", \"Aujourd\", \"'\", \"hui\", \"?\", \"!\", \",\", \".\", \"-\", \"/\", \"~\"\n",
    "]\n",
    "\n",
    "for word in words:\n",
    "    word_ = word.lower()\n",
    "    embedding = index_to_embedding[word_to_index[word_]]\n",
    "    norm = str(np.linalg.norm(embedding))\n",
    "    print((word + \": \").ljust(15) + norm)\n",
    "print(\"Note: here we printed words starting with capital letters, \\n\"\n",
    "      \"however to take their embeddings we need their lowercase version (str.lower())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the embedding in TensorFlow\n",
    "\n",
    "We simply create a non-trainable (frozen) tf.Variable() which we set to hold the value of the big embedding matrix.\n",
    "\n",
    "First, let's define the variables and graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = None  # Any size is accepted\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()  # sess = tf.Session()\n",
    "\n",
    "# Define the variable that will hold the embedding:\n",
    "tf_embedding = tf.Variable(\n",
    "    tf.constant(0.0, shape=index_to_embedding.shape),\n",
    "    trainable=False,\n",
    "    name=\"Embedding\"\n",
    ")\n",
    "\n",
    "tf_word_ids = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "\n",
    "tf_word_representation_layer = tf.nn.embedding_lookup(\n",
    "    params=tf_embedding,\n",
    "    ids=tf_word_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2196019), Dimension(300)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending the embedding to TensorFlow below. It will be located in the GPU from now (or on CPU if GPU is unavailable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding now stored in TensorFlow. Can delete numpy array to clear some CPU RAM.\n"
     ]
    }
   ],
   "source": [
    "tf_embedding_placeholder = tf.placeholder(tf.float32, shape=index_to_embedding.shape)\n",
    "tf_embedding_init = tf_embedding.assign(tf_embedding_placeholder)\n",
    "_ = sess.run(\n",
    "    tf_embedding_init, \n",
    "    feed_dict={\n",
    "        tf_embedding_placeholder: index_to_embedding\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Embedding now stored in TensorFlow. Can delete numpy array to clear some CPU RAM.\")\n",
    "del index_to_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use or fetch representations, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representations for ['Hello', 'World', '!']:\n",
      "[[ 2.5233e-01  1.0176e-01 -6.7485e-01  2.1117e-01  4.3492e-01  1.6542e-01\n",
      "   4.8261e-01 -8.1222e-01  4.1321e-02  7.8502e-01 -7.7857e-02 -6.6324e-01\n",
      "   1.4640e-01 -2.9289e-01 -2.5488e-01  1.9293e-02 -2.0265e-01  9.8232e-01\n",
      "   2.8312e-02 -8.1276e-02 -1.2140e-01  1.3126e-01 -1.7648e-01  1.3556e-01\n",
      "  -1.6361e-01 -2.2574e-01  5.5006e-02 -2.0308e-01  2.0718e-01  9.5785e-02\n",
      "   2.2481e-01  2.1537e-01 -3.2982e-01 -1.2241e-01 -4.0031e-01 -7.9381e-02\n",
      "  -1.9958e-01 -1.5083e-02 -7.9139e-02 -1.8132e-01  2.0681e-01 -3.6196e-01\n",
      "  -3.0744e-01 -2.4422e-01 -2.3113e-01  9.7980e-02  1.4630e-01 -6.2738e-02\n",
      "   4.2934e-01 -7.8038e-02 -1.9627e-01  6.5093e-01 -2.2807e-01 -3.0308e-01\n",
      "  -1.2483e-01 -1.7568e-01 -1.4651e-01  1.5361e-01 -2.9518e-01  1.5099e-01\n",
      "  -5.1726e-01 -3.3564e-02 -2.3109e-01 -7.8330e-01  1.8029e-02 -1.5719e-01\n",
      "   2.2930e-02  4.9639e-01  2.9225e-02  5.6690e-02  1.4616e-01 -1.9195e-01\n",
      "   1.6244e-01  2.3898e-01  3.6431e-01  4.5263e-01  2.4560e-01  2.3803e-01\n",
      "   3.1399e-01  3.4870e-01 -3.5791e-02  5.6108e-01 -2.5345e-01  5.1964e-02\n",
      "  -1.0618e-01 -3.0962e-01  1.0585e+00 -4.2025e-01  1.8216e-01 -1.1256e-01\n",
      "   4.0576e-01  1.1784e-01 -1.9705e-01 -7.5292e-02  8.0723e-02 -2.7820e-02\n",
      "  -1.5617e-01 -4.4681e-01 -1.5165e-01  1.6920e-01  9.8255e-02 -3.1894e-02\n",
      "   8.7143e-02  2.6082e-01  2.7060e-03  1.3190e-01  3.4439e-01 -3.7894e-01\n",
      "  -4.1140e-01  8.1571e-02 -1.1674e-01 -4.3711e-01  1.1144e-02  9.9353e-02\n",
      "   2.6612e-01  4.0025e-01  1.8895e-01 -1.8438e-01 -3.0355e-01 -2.7250e-01\n",
      "   2.2468e-01 -4.0614e-01  1.5618e-01 -1.6043e-01  4.7147e-01  8.0203e-03\n",
      "   5.6858e-01  2.1934e-01 -1.1181e-01  7.9925e-01  1.0714e-01 -5.0146e-01\n",
      "   6.3593e-02  6.9465e-02  1.5292e-01 -2.7470e-01 -2.0989e-01  2.0737e-01\n",
      "  -1.0681e-01  4.0651e-01 -2.6438e+00 -3.1139e-01 -3.2157e-01 -2.6458e-01\n",
      "  -3.5625e-01  7.0013e-02 -1.8838e-01  4.8773e-01 -2.6167e-01 -2.0805e-02\n",
      "   1.7819e-01  1.5758e-01 -1.3752e-01  5.6464e-02  3.0766e-01 -6.6136e-02\n",
      "   4.7480e-01 -2.7335e-01  9.7320e-02 -2.0832e-01  3.9332e-03  3.4600e-01\n",
      "  -8.7020e-02 -5.4924e-01 -1.8759e-01 -1.7174e-01  6.0324e-02 -1.3521e-01\n",
      "   1.0419e-01  3.0165e-01  5.7980e-02  2.1872e-01 -7.3594e-02 -2.0423e-01\n",
      "  -2.5279e-01 -1.0471e-01 -3.2163e-01  1.2525e-01 -3.1281e-01  9.7207e-03\n",
      "  -2.6777e-01 -6.1121e-01 -1.1089e-01 -1.3652e-01  3.5135e-02 -4.9390e-01\n",
      "   8.4857e-02 -1.5494e-01 -6.3509e-02 -2.3935e-01  2.8272e-01  1.0849e-01\n",
      "  -3.3650e-01 -6.0764e-01  3.8576e-01 -9.5438e-03  1.7499e-01 -5.2723e-01\n",
      "   6.2211e-01  1.9544e-01 -4.8977e-01  3.6582e-02 -1.2800e-01 -1.6827e-02\n",
      "   2.5647e-01 -3.1698e-01  4.8257e-01 -1.4184e-01  1.1046e-01 -3.0980e-01\n",
      "  -6.3141e-01 -3.7268e-01  2.3183e-01 -1.4268e-01 -2.3410e-02  2.2255e-02\n",
      "  -4.4662e-02 -1.6404e-01 -2.5848e-01  1.6290e-01  2.4751e-02  2.3348e-01\n",
      "   2.7933e-01  3.8998e-01 -5.8968e-02  1.1355e-01  1.5673e-01  1.8583e-01\n",
      "  -1.9814e-01 -4.8123e-01 -3.5084e-02  7.8458e-02 -4.9833e-01  1.0855e-01\n",
      "  -2.0133e-01  5.2920e-02 -1.1583e-01 -1.6009e-01  1.6768e-01  4.2362e-01\n",
      "  -2.3106e-01  8.2465e-02  2.4296e-01 -1.6786e-01  8.0409e-03  8.5947e-02\n",
      "   3.8033e-01  7.2981e-02  1.6330e-01  2.4704e-01 -1.1094e-01  1.5115e-01\n",
      "  -2.2068e-01 -6.1944e-02 -3.7091e-02 -8.7923e-02 -2.3181e-01  1.5035e-01\n",
      "  -1.9093e-01 -1.9113e-01 -1.1894e-01  9.4908e-02 -4.3347e-03  1.5362e-01\n",
      "  -4.1201e-01 -3.0730e-01  1.8375e-01  4.0206e-01 -3.4793e-03 -1.0917e-01\n",
      "  -6.9522e-01  1.0161e-01 -7.9256e-02  4.0329e-01  2.2285e-01 -1.9374e-01\n",
      "  -1.3315e-01  7.3231e-02  9.9832e-02  1.1685e-01 -2.1643e-01 -1.1080e-01\n",
      "   1.0341e-01  9.7286e-02  1.1196e-01 -3.8940e-01 -8.9363e-03  2.8809e-01\n",
      "  -1.0792e-01  2.8811e-02  3.2545e-01  2.6052e-01 -3.8941e-02  7.5204e-02\n",
      "   4.6031e-01 -6.2930e-02  2.1661e-01  1.7869e-01 -5.1917e-01  3.3591e-01]\n",
      " [-6.6796e-03  2.2238e-01  2.7709e-01 -1.6760e-01  3.9934e-01 -2.6935e-01\n",
      "   1.1758e-01  8.2171e-01 -2.9600e-01  2.7338e+00 -5.1854e-01 -3.9980e-01\n",
      "   4.5268e-02  7.0994e-02  3.8210e-01 -1.9731e-01 -4.1031e-01  9.1488e-01\n",
      "  -4.5642e-02  1.9991e-01  3.5154e-02  4.0459e-02  5.2444e-02  1.6124e-01\n",
      "   1.8280e-01 -1.5186e-01  3.1278e-01 -1.4228e-02 -7.5154e-02  6.3618e-01\n",
      "  -3.0658e-03  1.1577e-01 -1.5101e-02 -9.5193e-02  4.2313e-01 -3.5243e-01\n",
      "   1.5452e-01 -3.9491e-01  6.1847e-02  4.5658e-01  1.8395e-01 -3.4329e-02\n",
      "   8.0296e-02  2.1393e-01 -1.2170e-01  1.2957e-02 -2.3259e-01 -8.4731e-02\n",
      "   4.4998e-02 -1.4019e-01 -7.0056e-02 -1.2399e-01 -4.5609e-01 -1.0087e-01\n",
      "   3.9152e-01 -1.9437e-01  3.1484e-01 -2.4423e-01  7.8843e-01 -2.7220e-01\n",
      "   3.5652e-02  7.1816e-02 -9.9133e-02  1.0260e-02 -1.4698e-01  1.9898e-02\n",
      "   1.5508e-01 -9.4629e-02 -1.1017e-01  3.4240e-02 -1.9389e-01 -4.3287e-01\n",
      "   2.9240e-01  2.0294e-01 -4.4540e-01  3.3994e-01  8.8975e-03 -1.5746e-02\n",
      "   4.4674e-01  4.8578e-01  4.7199e-02  2.3850e-01 -1.7062e-01  1.3774e-01\n",
      "  -7.3939e-02 -8.5463e-01 -9.5668e-01 -2.5329e-01 -1.1777e-01 -1.1812e-01\n",
      "  -5.2252e-01  2.0321e-01 -6.3754e-01  1.3490e-01 -1.8466e-01 -1.8157e-01\n",
      "   2.6867e-02 -2.1901e-02  2.6663e-01  2.7428e-01  3.3822e-01  8.2030e-02\n",
      "  -2.8889e-01 -7.3748e-02 -8.9901e-03 -1.0196e+00 -1.5378e-02  9.8236e-02\n",
      "  -1.8926e-01  1.0841e-01  2.5414e-01 -2.0826e-01 -7.5681e-02 -2.2413e-01\n",
      "  -1.8159e-01  4.6597e-01  2.0012e-01  2.8821e-01 -6.3588e-02 -2.5630e-01\n",
      "  -2.1808e-01 -1.5706e-01  2.6271e-01 -4.1973e-01  1.0095e-01  1.6371e-01\n",
      "   2.2834e-01 -1.2602e-01  3.7693e-01 -2.3717e-01  4.2714e-01 -1.2639e-01\n",
      "   2.1220e-01 -3.8119e-01 -9.5456e-02 -2.6961e-01 -1.3042e-01 -2.1551e-01\n",
      "  -1.8953e-01  3.0259e-01 -1.9741e+00 -5.2030e-01  2.9876e-01  5.7871e-02\n",
      "   2.1359e-01 -3.4952e-01  5.3584e-01  3.6520e-01 -3.7080e-01 -6.3623e-02\n",
      "   2.5807e-01 -2.6754e-02  3.1513e-01  2.6846e-01  6.5093e-02  2.5803e-04\n",
      "  -1.3588e-01  2.4980e-01 -1.3909e-01  1.1234e-01  3.3316e-01  3.4609e-01\n",
      "  -3.0484e-02  1.9027e-01  2.0124e-01 -2.0287e-01  3.0843e-01 -4.6492e-01\n",
      "   2.7708e-01  2.9172e-01 -9.7622e-03 -3.0099e-01  7.6570e-02 -9.7341e-02\n",
      "  -1.2393e-01  1.4921e-01 -1.6147e-01 -1.7466e-01 -1.5586e-01  2.1108e-01\n",
      "   4.9188e-01  2.9547e-01  1.4422e-01 -3.3139e-01  2.6869e-03 -3.2858e-01\n",
      "   5.1358e-03 -1.0870e-01  1.9086e-02 -7.8923e-02 -4.0630e-01 -2.0526e-01\n",
      "   4.2546e-01  2.9473e-01 -2.9929e-01  6.7783e-02  1.7279e-01  1.6008e-01\n",
      "   1.9886e-01  4.5809e-02  7.2766e-02 -8.6075e-02  3.4542e-01  2.8371e-01\n",
      "   3.5538e-01 -2.5499e-01  3.1744e-01  5.9334e-03 -3.7372e-01 -2.0612e-01\n",
      "  -5.2648e-01 -7.4487e-01  1.1757e-02 -3.0472e-01  2.6317e-02 -1.3342e-01\n",
      "   3.0670e-01 -2.5618e-01 -1.8582e-01  1.9382e-02 -2.9999e-01  2.0616e-01\n",
      "   1.8106e-01 -1.3167e-01 -3.1513e-01  2.1602e-01  8.3713e-03  3.5770e-01\n",
      "  -4.7267e-01  3.9963e-01  5.3379e-02  1.7932e-01  2.6909e-02 -4.4594e-02\n",
      "  -2.9042e-01  9.6057e-02 -6.7086e-01 -1.8504e-01 -3.7122e-01 -3.7638e-01\n",
      "   2.4558e-01  2.5896e-01  1.7423e-01  2.3388e-01 -4.0986e-02 -2.2366e-01\n",
      "  -2.4149e-01  3.3690e-01 -5.1075e-01 -3.7846e-02  3.4640e-01 -2.8095e-01\n",
      "   7.0234e-02  1.5570e-02 -1.6339e-01 -4.6059e-03  2.3066e-01  3.4541e-01\n",
      "  -1.0091e-01  3.8429e-01  2.1258e-01  2.6249e-01 -2.2807e-01  1.6382e-01\n",
      "   1.3648e-02 -6.0375e-01 -1.5751e-01 -1.1807e-01  6.0896e-01  4.4867e-01\n",
      "  -6.8183e-01 -3.7484e-01 -2.6337e-01  1.9173e-02  1.4897e-01 -9.4622e-02\n",
      "  -8.9517e-02  2.5521e-01  1.9849e-01 -3.1701e-01  4.1117e-02 -3.1162e-01\n",
      "   6.1004e-02 -5.2715e-03 -1.0638e-01 -2.7631e-01  2.1142e-02 -1.1392e-01\n",
      "   2.4777e-02 -6.5339e-02 -6.2834e-01 -1.4461e-02 -1.4295e-01 -2.0125e-01\n",
      "  -6.6727e-02  3.7398e-01  3.1205e-02  5.9372e-02  1.4085e-03  9.8727e-02]\n",
      " [-2.6554e-01  3.3531e-01  2.1860e-01 -3.0100e-01 -5.5470e-02 -2.4236e-01\n",
      "   1.7236e-01 -1.6334e-01 -1.0900e-01  1.2671e+00 -3.3449e-01  2.0911e-01\n",
      "  -1.0205e-02  2.7530e-01 -1.8455e-01  1.7111e-02 -3.7401e-02  1.3706e+00\n",
      "  -1.7785e-01 -1.5351e-01  9.9583e-02 -3.1839e-01  7.7433e-02  4.9495e-02\n",
      "  -5.3451e-02 -3.4892e-02  1.6875e-01  2.8741e-02  2.0523e-01 -1.0273e-01\n",
      "   1.2935e-01  3.5585e-01  4.0188e-03  7.9254e-02  2.4425e-01  2.7667e-01\n",
      "   8.0892e-02  3.0308e-01 -8.5076e-02  1.0352e-03  1.2730e-01  1.1868e-01\n",
      "   2.0868e-01 -1.4019e-01  2.4865e-01  3.1383e-01 -5.5654e-01  8.6916e-02\n",
      "   4.0284e-01  3.6714e-02  1.4341e-01  3.0447e-01  1.7679e-01 -2.0325e-01\n",
      "  -8.6745e-02 -5.9375e-02  1.0775e-01  2.6919e-01  3.6491e-02  1.2037e-01\n",
      "  -1.8979e-01  1.9414e-01 -1.8552e-02 -4.5914e-01  1.2681e-01 -5.4521e-02\n",
      "  -2.2054e-01  1.1147e-01  8.4313e-03  2.0667e-01  3.1060e-01 -9.2659e-02\n",
      "   3.1766e-01  1.6209e-01  4.5862e-01  1.1182e-04 -8.8286e-02 -3.7030e-01\n",
      "   5.3689e-02  7.9508e-01 -2.4994e-01  4.3256e-01  8.8471e-02  4.1864e-01\n",
      "   1.1771e-01  4.6896e-02  5.3549e-01 -8.6838e-01  1.5809e-01  4.9917e-01\n",
      "   2.6179e-01  5.2140e-01  3.5645e-01  1.4372e-01 -3.6987e-01 -1.4000e-01\n",
      "  -6.2828e-01 -3.1675e-01 -1.9247e-02 -7.4357e-02  2.0714e-01 -1.5843e-01\n",
      "  -2.9743e-01 -2.1549e-01  8.0076e-02  1.1832e+00  4.8673e-01  1.4721e-01\n",
      "   1.2630e-01  2.6231e-02  3.6053e-01 -6.8196e-01  5.5184e-01  6.1528e-02\n",
      "   3.3425e-03  4.8489e-02  1.3825e-01 -1.5156e-01 -6.9840e-02 -9.9947e-02\n",
      "   2.3865e-01  1.3611e-01  2.6055e-01 -4.4013e-02  2.5868e-02 -2.7526e-01\n",
      "  -8.4552e-02  4.6746e-02  8.6153e-02 -1.8508e-01 -9.3114e-02 -5.9787e-01\n",
      "  -2.5463e-01  8.2126e-02 -1.4104e-01  2.4358e-01 -2.4225e-01  2.9690e-01\n",
      "  -1.6202e-01  6.0339e-01 -2.0813e+00  5.5412e-01  7.6675e-01 -1.9920e-01\n",
      "   3.2305e-01 -1.7755e-01 -1.6761e-01  3.8451e-01 -3.4128e-01  3.8295e-02\n",
      "  -2.0701e-01  8.7338e-01 -2.2934e-01 -1.4054e-01  4.9033e-01 -3.6845e-01\n",
      "   2.6926e-01 -4.0554e-01  3.4307e-01 -1.7314e-01  1.8955e-01 -1.5305e-01\n",
      "  -7.7203e-02 -3.4467e-01  9.9602e-02  2.4910e-01 -1.5662e-01 -1.4328e-01\n",
      "   3.2020e-02  5.7149e-01 -9.7738e-03 -8.4682e-02 -3.1799e-01  1.0101e-01\n",
      "  -1.6099e-01  6.6370e-02  2.5543e-01  1.5427e-01 -3.7382e-01 -1.0029e-01\n",
      "  -2.4851e-01 -9.9441e-02 -1.6696e-01 -2.5520e-01 -2.6483e-01 -5.4984e-01\n",
      "  -4.7636e-01 -3.0128e-01  1.9842e-01  6.2700e-02 -1.1024e-01 -2.1813e-01\n",
      "   3.3200e-01  2.7030e-01  2.4467e-02  2.2990e-01  2.9060e-03 -3.2990e-01\n",
      "   7.4210e-01  1.7305e-01 -3.4286e-01  1.0717e-01  2.5081e-01 -5.1652e-02\n",
      "   2.1430e-01  5.6340e-02 -5.5078e-02  2.3547e-01  9.8905e-02 -4.9870e-01\n",
      "  -4.0825e-02 -4.3741e-01 -1.5599e-01  1.2596e-01 -5.2259e-03  4.2925e-01\n",
      "   3.7281e-01 -5.4302e-02 -5.4095e-01  3.6250e-01 -3.0536e-01  1.4411e-01\n",
      "  -2.7903e-01  4.5630e-02  2.7276e-01 -4.9394e-02 -3.0396e-01  5.3267e-01\n",
      "  -6.6274e-03 -1.0888e-01  1.2579e-01 -3.4876e-01 -1.7502e-01 -2.6133e-02\n",
      "   2.5876e-02  4.6289e-01 -1.1516e-01 -1.9461e-01 -1.7781e-01 -1.8374e-01\n",
      "   2.0147e-01 -2.1280e-01 -1.5289e-01  1.7298e-01  2.2503e-01 -9.5777e-02\n",
      "  -7.4261e-02  5.2321e-02  1.6853e-01  5.8565e-01  2.7345e-02  1.2770e-01\n",
      "  -4.0630e-01 -1.3299e-01 -2.1093e-01  5.9611e-01  1.7409e-01  1.2483e-01\n",
      "  -1.5014e-01 -4.6455e-02 -1.0728e-02 -1.4175e-01 -3.8314e-01  4.1410e-02\n",
      "  -2.5619e-01 -4.2536e-02  3.5050e-01 -2.4369e-01  5.3533e-01  2.5372e-01\n",
      "  -5.9328e-01 -1.6591e-02 -7.2031e-01  9.2813e-02 -4.5688e-01 -1.0833e-01\n",
      "  -3.8946e-02 -3.5834e-02  2.0215e-01  4.0055e-01  3.7802e-01 -1.2920e-01\n",
      "  -9.1766e-03 -1.0482e-02  4.3290e-02  1.3123e-01  3.3219e-01  1.5346e-01\n",
      "   3.5997e-02 -8.3019e-03 -3.8645e-01 -1.5056e-01 -3.2827e-02 -1.0529e-01\n",
      "   2.8397e-01 -2.5500e-01  1.5195e-01 -1.7859e-01 -6.2878e-02  1.6232e-01]]\n"
     ]
    }
   ],
   "source": [
    "batch_of_words = [\"Hello\", \"World\", \"!\"]\n",
    "batch_indexes = [word_to_index[w.lower()] for w in batch_of_words]\n",
    "\n",
    "embedding_from_batch_lookup = sess.run(\n",
    "    tf_word_representation_layer, \n",
    "    feed_dict={\n",
    "        tf_word_ids: batch_indexes\n",
    "    }\n",
    ")\n",
    "print(\"Representations for {}:\".format(batch_of_words))\n",
    "print(embedding_from_batch_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To avoid loading the embedding twice in RAM, make TensorFlow able to load them from disks directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\964864\\AppData\\Local\\Temp\\1\\ipykernel_22280\\270876442.py:11: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "TF embeddings saved to 'embeddings\\glove.840B.300d.ckpt'.\n",
      "word_to_index dict saved to 'embeddings\\glove.840B.300d.json'.\n"
     ]
    }
   ],
   "source": [
    "if CHAKIN_INDEX == 2:\n",
    "    prefix = FILE_NAME\n",
    "elif CHAKIN_INDEX == 16:\n",
    "    prefix = SUBFOLDER_NAME\n",
    "elif CHAKIN_INDEX == 17:\n",
    "    prefix = SUBFOLDER_NAME + \".\" + str(NUMBER_OF_DIMENSIONS) + \"d\"\n",
    "TF_EMBEDDINGS_FILE_NAME = os.path.join(DATA_FOLDER, prefix + \".ckpt\")\n",
    "DICT_WORD_TO_INDEX_FILE_NAME = os.path.join(DATA_FOLDER, prefix + \".json\")\n",
    "\n",
    "variables_to_save = [tf_embedding]\n",
    "embedding_saver = tf.train.Saver(variables_to_save)\n",
    "embedding_saver.save(sess, save_path=TF_EMBEDDINGS_FILE_NAME)\n",
    "print(\"TF embeddings saved to '{}'.\".format(TF_EMBEDDINGS_FILE_NAME))\n",
    "sess.close()\n",
    "\n",
    "with open(DICT_WORD_TO_INDEX_FILE_NAME, 'w') as f:\n",
    "    json.dump(word_to_index, f)\n",
    "print(\"word_to_index dict saved to '{}'.\".format(DICT_WORD_TO_INDEX_FILE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like absolutely crazy not hate bag sand rock soap\n",
      "[4512, 108, 5364, 1939, 2196018, 6, 1504, 269, 2476, 4512, 1042, 1161, 1939, 4512, 2937, 2196018, 1825, 3228, 6, 9279, 2937, 2196018, 1479, 2476, 1161, 2196018, 4127, 6, 1161, 1939, 2196018, 1504, 6, 3577, 2196018, 269, 6, 1479, 1674, 2196018, 3228, 2476, 1825, 5364, 2196018, 269, 2476, 6, 3523]\n"
     ]
    }
   ],
   "source": [
    "words_B = \"like absolutely crazy not hate bag sand rock soap\"\n",
    "r = [word_to_index[w.strip()] for w in words_B]\n",
    "print(words_B)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model to get word similarities from word A to a list of many words B\n",
    "\n",
    "This is for demo purposes. With a GPU, we can fetch many words quickly and compute on them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restarting from scratch: resetting the Jupyter notebook and loading embeddings from disks, the good way\n",
    "\n",
    "Now that we have a TensorFlow checkpoint, let's load the embedding without having to parse the txt file into NumPy in CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic iPython/Jupyter command to delete variables and restart the Python kernel\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "import tensorflow.compat.v1 as tf # REPLACED !!!!!\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = None  # Any size is accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER THE INDEX YOU WISH TO USE\n",
    "# Use 2 for the 300 dimension embeddings created using fastText on Wikipedia data\n",
    "# Use 17 for the 25 dimension embeddings created using GloVe on Twitter data\n",
    "# Other embedding schemes are not supported and may require further code modification to work\n",
    "\n",
    "CHAKIN_INDEX = 16\n",
    "\n",
    "if CHAKIN_INDEX == 2:\n",
    "    word_representations_dimensions = 300  # Embedding of size (vocab_len, nb_dimensions)\n",
    "\n",
    "    DATA_FOLDER = \"embeddings\"\n",
    "    FILE_NAME = \"cc.en.300.vec\" \n",
    "    TF_EMBEDDING_FILE_NAME = \"{}.ckpt\".format(FILE_NAME) #cc.en.300.vec.ckpt\n",
    "    SUFFIX = FILE_NAME  # cc.en.300.vec\n",
    "    TF_EMBEDDINGS_FILE_PATH = os.path.join(DATA_FOLDER, SUFFIX + \".ckpt\")  # embeddings\\cc.en.300.vec.ckpt\n",
    "    DICT_WORD_TO_INDEX_FILE_NAME = os.path.join(DATA_FOLDER, SUFFIX + \".json\") # embeddings\\cc.en.300.vec.json\n",
    "elif CHAKIN_INDEX == 16:\n",
    "    word_representations_dimensions = 300  # Embedding of size (vocab_len, nb_dimensions)\n",
    "    DATA_FOLDER = \"embeddings\"\n",
    "    SUBFOLDER_NAME = \"glove.840B.300d\"\n",
    "    TF_EMBEDDING_FILE_NAME = \"{}.ckpt\".format(SUBFOLDER_NAME) #glove.840B.300d.ckpt\n",
    "    TF_EMBEDDINGS_FILE_PATH = os.path.join(DATA_FOLDER, TF_EMBEDDING_FILE_NAME)  # embeddings\\glove.840B.300d.ckpt\n",
    "    DICT_WORD_TO_INDEX_FILE_NAME = os.path.join(DATA_FOLDER, SUBFOLDER_NAME + \".json\") # embeddings\\glove.840B.300d.json\n",
    "elif CHAKIN_INDEX == 17:\n",
    "    word_representations_dimensions = 25  # Embedding of size (vocab_len, nb_dimensions)\n",
    "\n",
    "    DATA_FOLDER = \"embeddings\"\n",
    "    SUBFOLDER_NAME = \"glove.twitter.27B\"\n",
    "    TF_EMBEDDING_FILE_NAME = \"{}.ckpt\".format(SUBFOLDER_NAME) # glove.twitter.27B.ckpt\n",
    "    SUFFIX = SUBFOLDER_NAME + \".\" + str(word_representations_dimensions) # glove.twitter.27B.25\n",
    "    TF_EMBEDDINGS_FILE_PATH = os.path.join(DATA_FOLDER, SUFFIX + \"d.ckpt\") # embeddings/glove.twitter.27B.25d.ckpt\n",
    "    DICT_WORD_TO_INDEX_FILE_NAME = os.path.join(DATA_FOLDER, SUFFIX + \"d.json\")\n",
    "else:\n",
    "    print(\"Those embeddings are not currently supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_to_index dict restored from 'embeddings\\glove.840B.300d.json'.\n",
      "INFO:tensorflow:Restoring parameters from embeddings\\glove.840B.300d.ckpt\n",
      "TF embeddings restored from 'embeddings\\glove.840B.300d.ckpt'.\n",
      "Model created.\n"
     ]
    }
   ],
   "source": [
    "def load_word_to_index(dict_word_to_index_file_name):\n",
    "    \"\"\"\n",
    "    Load a `word_to_index` dict mapping words to their id, with a default value\n",
    "    of pointing to the last index when not found, which is the unknown word.\n",
    "    \"\"\"\n",
    "    with open(dict_word_to_index_file_name, 'r') as f:\n",
    "        word_to_index = json.load(f)\n",
    "    # The provided method of calculating _LAST_INDEX does not work for all embeddings\n",
    "    _LAST_INDEX = np.array(list(word_to_index.values())).max() \n",
    "    print(\"word_to_index dict restored from '{}'.\".format(dict_word_to_index_file_name))\n",
    "    word_to_index = defaultdict(lambda: _LAST_INDEX, word_to_index)\n",
    "\n",
    "    return word_to_index\n",
    "\n",
    "def load_embedding_tf(word_to_index, tf_embeddings_file_path, nb_dims):\n",
    "    \"\"\"\n",
    "    Define the embedding tf.Variable and load it.\n",
    "    \"\"\"\n",
    "    # You need to subtract a number from len(word_to_index) below for the code to work\n",
    "    # (I don't know why)\n",
    "    # The number differs \n",
    "\n",
    "    # 1. Define the variable that will hold the embedding:\n",
    "    # Was originally len(word_to_index)-1, but subtracting -1 isn't even right for the twitter embedding,\n",
    "    # and the number to subtract differs based on which embedding is used\n",
    "    tf_embedding = tf.Variable(\n",
    "        tf.constant(0.0, shape=[np.array(list(word_to_index.values())).max() + 1, nb_dims]),\n",
    "        trainable=False,\n",
    "        name=\"Embedding\"\n",
    "    )\n",
    "\n",
    "    # print(\"BEFORE\")\n",
    "    # print(type(tf_embedding))\n",
    "    # print(tf_embedding.shape)\n",
    "    # print(\"AFTER\")\n",
    "\n",
    "    # 2. Restore the embedding from disks to TensorFlow, GPU (or CPU if GPU unavailable):\n",
    "    variables_to_restore = [tf_embedding]\n",
    "    embedding_saver = tf.train.Saver(variables_to_restore)\n",
    "    embedding_saver.restore(sess, save_path=tf_embeddings_file_path)\n",
    "    print(\"TF embeddings restored from '{}'.\".format(tf_embeddings_file_path))\n",
    "    \n",
    "    return tf_embedding\n",
    "    \n",
    "def cosine_similarity_tensorflow(tf_word_representation_A, tf_words_representation_B):\n",
    "    \"\"\"\n",
    "    Returns the `cosine_similarity = cos(angle_between_a_and_b_in_space)` \n",
    "    for the two word A to all the words B.\n",
    "    The first input word must be a 1D Tensors (word_representation).\n",
    "    The second input words must be 2D Tensors (batch_size, word_representation).\n",
    "    The result is a tf tensor that must be fetched with `sess.run`.\n",
    "    \"\"\"\n",
    "    a_normalized = tf.nn.l2_normalize(tf_word_representation_A, axis=-1)\n",
    "    b_normalized = tf.nn.l2_normalize(tf_words_representation_B, axis=-1)\n",
    "    similarity = tf.reduce_sum(\n",
    "        tf.multiply(a_normalized, b_normalized), \n",
    "        axis=-1\n",
    "    )\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "\n",
    "# In case you didn't do the \"%reset\": \n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()  # sess = tf.Session()\n",
    "\n",
    "# Load the embedding matrix in tf\n",
    "word_to_index = load_word_to_index(\n",
    "    DICT_WORD_TO_INDEX_FILE_NAME)\n",
    "tf_embedding = load_embedding_tf(\n",
    "    word_to_index,\n",
    "    TF_EMBEDDINGS_FILE_PATH, \n",
    "    word_representations_dimensions)\n",
    "\n",
    "# Input to the graph where word IDs can be sent in batch. Look at the \"shape\" args:\n",
    "tf_word_A_id = tf.placeholder(tf.int32, shape=[1])\n",
    "tf_words_B_ids = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "\n",
    "# Conversion of words to a representation\n",
    "tf_word_representation_A = tf.nn.embedding_lookup(\n",
    "    params=tf_embedding, ids=tf_word_A_id)\n",
    "tf_words_representation_B = tf.nn.embedding_lookup(\n",
    "    params=tf_embedding, ids=tf_words_B_ids)\n",
    "\n",
    "# The graph output are the \"cosine_similarities\" which we want to fetch in sess.run(...). \n",
    "cosine_similarities = cosine_similarity_tensorflow(\n",
    "    tf_word_representation_A, \n",
    "    tf_words_representation_B)\n",
    "\n",
    "print(\"Model created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the fetch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities with \"Science\":\n",
      "    hello:         0.10984746366739273\n",
      "    internet:      0.29033395648002625\n",
      "    ,:             0.21967126429080963\n",
      "    a:             0.22639356553554535\n",
      "    vocano:        0.0\n",
      "    erupt:         0.06329665333032608\n",
      "    like:          0.31537872552871704\n",
      "    the:           0.30549389123916626\n",
      "    bitcoin:       -0.002926294459030032\n",
      "    out:           0.2886187732219696\n",
      "    of:            0.3249181807041168\n",
      "    the:           0.30549389123916626\n",
      "    blue:          0.1310815066099167\n",
      "    and:           0.2947123050689697\n",
      "    there:         0.3527158498764038\n",
      "    is:            0.30085262656211853\n",
      "    an:            0.252271831035614\n",
      "    unknownword00: 0.0\n",
      "    !:             0.16768565773963928\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_word_ids(sentence, word_to_index):\n",
    "    \"\"\"\n",
    "    Note: there might be a better way to split sentences for GloVe.\n",
    "    Please look at the documentation or open an issue to suggest a fix.\n",
    "    \"\"\"\n",
    "    # Separating punctuation from words:\n",
    "    for punctuation_character in punctuation:\n",
    "        sentence = sentence.replace(punctuation_character, \" {} \".format(punctuation_character))\n",
    "    # Removing double spaces and lowercasing:\n",
    "    sentence = sentence.replace(\"  \", \" \").replace(\"  \", \" \").lower().strip()\n",
    "    # Splitting on every space:\n",
    "    split_sentence = sentence.split(\" \")\n",
    "    # Converting to IDs:\n",
    "    ids = [(word_to_index[w.strip()]) for w in split_sentence] \n",
    "    return ids, split_sentence\n",
    "\n",
    "def predict_cosine_similarities(sess, word_A, words_B):\n",
    "    \"\"\"\n",
    "    Use the model in sess to predict cosine similarities.\n",
    "    \"\"\"\n",
    "\n",
    "    word_A_id, _ = sentence_to_word_ids(word_A, word_to_index)\n",
    "    words_B_ids, split_sentence = sentence_to_word_ids(words_B, word_to_index)\n",
    "\n",
    "    evaluated_cos_similarities = sess.run(\n",
    "        cosine_similarities, \n",
    "        feed_dict={\n",
    "            tf_word_A_id: word_A_id,\n",
    "            tf_words_B_ids: words_B_ids\n",
    "        }\n",
    "    )\n",
    "    return evaluated_cos_similarities, split_sentence\n",
    "\n",
    "\n",
    "word_A = \"Science\"\n",
    "words_B = \"Hello internet, a vocano erupt like the bitcoin out of the blue and there is an unknownWord00!\"\n",
    "\n",
    "evaluated_cos_similarities, splitted = predict_cosine_similarities(sess, word_A, words_B)\n",
    "\n",
    "print(\"Cosine similarities with \\\"{}\\\":\".format(word_A))\n",
    "for word, similarity in zip(splitted, evaluated_cos_similarities):\n",
    "    print(\"    {}{}\".format((word+\":\").ljust(15), similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the top k most similars words to a word with the embedding matrix\n",
    "\n",
    "Let's take an input word and compare it to every other words in the embedding matrix to return the most similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\964864\\OneDrive - Cognizant HealthCare\\Documents\\Innovation Project\\Unified GloVe\\.venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1793: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_to_index dict restored from 'embeddings\\glove.840B.300d.json'.\n",
      "INFO:tensorflow:Restoring parameters from embeddings\\glove.840B.300d.ckpt\n",
      "TF embeddings restored from 'embeddings\\glove.840B.300d.ckpt'.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Transpose word_to_index dict:\n",
    "index_to_word = dict((val, key) for key, val in word_to_index.items())\n",
    "\n",
    "# New graph\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Load the embedding matrix in tf\n",
    "tf_word_to_index = load_word_to_index(\n",
    "    DICT_WORD_TO_INDEX_FILE_NAME)\n",
    "tf_embedding = load_embedding_tf(\n",
    "    tf_word_to_index,\n",
    "    TF_EMBEDDINGS_FILE_PATH, \n",
    "    word_representations_dimensions)\n",
    "\n",
    "# An input word \n",
    "tf_word_id = tf.placeholder(tf.int32, shape=[1])\n",
    "tf_word_representation = tf.nn.embedding_lookup(\n",
    "    params=tf_embedding, ids=tf_word_id)\n",
    "\n",
    "# An input \n",
    "tf_nb_similar_words_to_get = tf.placeholder(tf.int32)\n",
    "\n",
    "# Dot the word to every embedding\n",
    "tf_all_cosine_similarities = cosine_similarity_tensorflow(\n",
    "    tf_word_representation, \n",
    "    tf_embedding)\n",
    "\n",
    "# Getting the top cosine similarities. \n",
    "tf_top_cosine_similarities, tf_top_word_indices = tf.nn.top_k(\n",
    "    tf_all_cosine_similarities,\n",
    "    k=tf_nb_similar_words_to_get+1,\n",
    "    sorted=True\n",
    ")\n",
    "\n",
    "# Discard the first word because it's the input word itself:\n",
    "tf_top_cosine_similarities = tf_top_cosine_similarities[1:]\n",
    "tf_top_word_indices = tf_top_word_indices[1:]\n",
    "\n",
    "# Get the top words' representations by fetching \n",
    "# tf_top_words_representation = \"tf_embedding[tf_top_word_indices]\":\n",
    "tf_top_words_representation = tf.gather(\n",
    "    tf_embedding,\n",
    "    tf_top_word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar words to \"king\":\n",
      "\n",
      "kings:          0.7876614,      7.1117706\n",
      "prince:         0.73377365,     6.5258965\n",
      "queen:          0.72526103,     6.82974\n",
      "King:           0.71067923,     6.142591\n",
      "throne:         0.67260045,     7.1247444\n",
      "kingdom:        0.66040456,     6.905996\n",
      "lord:           0.64396936,     6.844843\n",
      "royal:          0.6168811,      6.81116\n",
      "reign:          0.6128068,      6.4697604\n",
      "princes:        0.59786516,     7.16161\n"
     ]
    }
   ],
   "source": [
    "# Fetch 10 similar words:\n",
    "nb_similar_words_to_get = 10\n",
    "\n",
    "word = \"king\"\n",
    "word_id = word_to_index[word]\n",
    "\n",
    "top_cosine_similarities, top_word_indices, top_words_representation = sess.run(\n",
    "    [tf_top_cosine_similarities, tf_top_word_indices, tf_top_words_representation],\n",
    "    feed_dict={\n",
    "        tf_word_id: [word_id],\n",
    "        tf_nb_similar_words_to_get: nb_similar_words_to_get\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Top similar words to \\\"{}\\\":\\n\".format(word))\n",
    "loop = zip(top_cosine_similarities, top_word_indices, top_words_representation)\n",
    "for cos_sim, word_id, word_repr in loop:\n",
    "    print(\n",
    "        (index_to_word[word_id]+ \":\").ljust(15),\n",
    "        (str(cos_sim) + \",\").ljust(15),\n",
    "        np.linalg.norm(word_repr)\n",
    "    )\n",
    "\n",
    "# MOST SIMILAR WORDS WORKED W/O CHANGES!!!!?????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the bad quality of the similar words, embeddings with more dimensions than 25 would make it better. \n",
    "\n",
    "Reminder: we chose 25 dimensions for tutorial purposes not to eat all our RAM. There are better embeddings out there.\n",
    "\n",
    "### Jeremy: \n",
    "\n",
    "The most similar words seem to be better for the 300-dimension embeddings created using fastText on Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What's next?\n",
    "\n",
    "I think getting the embeddings into TensorFlow is a good step into building a language model. You may want to grab some data, such as [here](https://github.com/awesomedata/awesome-public-datasets#naturallanguage) and [here](https://github.com/niderhoff/nlp-datasets). You may also want to learn more about how recurrent neural networks can read features such as sentences or signal of varying length, such as [an LSTM (RNN) encoder reading signal](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition) or an [signal predictor from a seq2seq GRU (RNN)](https://github.com/guillaume-chevalier/seq2seq-signal-prediction) which could be used in practice to [predict next words in a sentence](https://blog.openai.com/unsupervised-sentiment-neuron/). Since signal is closely related to sentences with embedded words, RNNs can be applied on both. \n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "The pretrained word vectors can be found there: \n",
    "- Repo https://github.com/stanfordnlp/GloVe\n",
    "- Manual download: http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "\n",
    "Chakin was used to download those word embeddings: \n",
    "- https://github.com/chakki-works/chakin\n",
    "\n",
    "Some images in this notebook are references/links from the TensorFlow website: \n",
    "- https://www.tensorflow.org/\n",
    "\n",
    "To cite my work, point to the URL of the GitHub repository: \n",
    "- https://github.com/guillaume-chevalier/GloVe-as-TensorFlow-Embedding\n",
    "\n",
    "My code is available under the [MIT License](https://github.com/guillaume-chevalier/GloVe-as-TensorFlow-Embedding/blob/master/LICENSE). \n",
    "\n",
    "## Connect with me\n",
    "\n",
    "- https://ca.linkedin.com/in/chevalierg \n",
    "- https://twitter.com/guillaume_che\n",
    "- https://github.com/guillaume-chevalier/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's convert this notebook to a README for the GitHub project's title page:\n",
    "# !ipython3 nbconvert --to markdown \"GloVe-as-TensorFlow-Embedding-Tutorial.ipynb\"\n",
    "# !mv \"GloVe-as-TensorFlow-Embedding-Tutorial.md\" README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
